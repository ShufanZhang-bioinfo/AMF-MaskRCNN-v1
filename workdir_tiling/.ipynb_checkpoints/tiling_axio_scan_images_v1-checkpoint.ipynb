{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2597aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import uuid as uuid\n",
    "import cv2\n",
    "import re\n",
    "import shutil\n",
    "from operator import itemgetter\n",
    "import math\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import shapely\n",
    "import shapely.geometry\n",
    "from shapely.geometry import Polygon,MultiPolygon,GeometryCollection\n",
    "from shapely.validation import make_valid\n",
    "from shapely.geometry import mapping\n",
    "import geopandas as gpd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9254c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main code BLOCK 1\n",
    "## listing directory structure\n",
    "projdir='/Users/lovely_shufan/Documents/image_analysis'   #working directory\n",
    "img_dir=projdir+'axio_scan_raw_images/' #input: image directory\n",
    "output_dir=projdir+'ouput/'           #output: tiled image directory\n",
    "preproc_dir=projdir+'preprocess/'      #intermediate: \n",
    "data_sep_dir=projdir+'datasep/'        #intermediate:\n",
    "qc_dir=projdir+'qc/'                   #intermediate: quality check\n",
    "\n",
    "## making directories \n",
    "os.makedirs(output_dir,exist_ok=True)\n",
    "os.makedirs(preproc_dir,exist_ok=True)\n",
    "os.makedirs(data_sep_dir,exist_ok=True)\n",
    "os.makedirs(qc_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c6dc0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAnnotation(img_dir):\n",
    "    '''\n",
    "    :param img_dir: image folder\n",
    "    :return list of dictionaries: annotation table and file list\n",
    "    '''\n",
    "    anno_file=os.path.join(img_dir,\"TrainingSet003_Arline_annotation_via_project_20July23_12.28pm_csv.csv\")\n",
    "    annotab=pd.read_csv(anno_file,delimiter=\",\")\n",
    "    files=annotab['filename'].unique()\n",
    "    return annotab, files\n",
    "\n",
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    \n",
    "def noHolePolygon(polygon):\n",
    "    # convert new annotations from polygons to points\n",
    "    exterior = list(polygon.exterior.coords)[:-1] #remove the last point which is the same as the first point\n",
    "    interior = list(polygon.interiors)\n",
    "                \n",
    "    if interior != []:\n",
    "        # merge interior point/linearring with exterior points\n",
    "        interior = GeometryCollection(interior)\n",
    "        for geom in interior.geoms: \n",
    "            for i in mapping(geom)['coordinates'][:-1]:\n",
    "                exterior.append(i)\n",
    "    return exterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b35ae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## changed working directory to output_dir\n",
    "os.chdir(output_dir) \n",
    "\n",
    "## read in annotation csv file and image file names\n",
    "annotab,files=readAnnotation(img_dir)\n",
    "#print(annotab.shape)\n",
    "\n",
    "## preprocess the annotation table\n",
    "classes=['AMF arbuscule island','AMF arbuscule cluster']\n",
    "\n",
    "### drop template images\n",
    "exclude_file = ['Snap-12327-Image Export-127.jpg', 'Snap-12291-Image Export-91.jpg','Snap-12220-Image Export-20.jpg']\n",
    "annotab = annotab[~annotab['filename'].isin(exclude_file)]\n",
    "#print(annotab['filename'].unique())\n",
    "#print(annotab['region_attributes'].unique())\n",
    "#print(annotab.shape)\n",
    "\n",
    "### remove unnecessary annotations based on class\n",
    "exclude_anno = ['{\"object\":\"AMF internal hypha\"}', '{}']\n",
    "annotab = annotab[~annotab['region_attributes'].isin(exclude_anno)]\n",
    "#print(annotab.shape)\n",
    "#print(annotab['region_attributes'].unique())\n",
    "\n",
    "rem = annotab['region_attributes'].unique()\n",
    "files = annotab['filename'].unique()\n",
    "\n",
    "\n",
    "\n",
    "annotab.to_csv(preproc_dir+'TrainingSet003_Arline_annotation_via_project_20July23_12.28pm_csv_preprocessed.csv',index=False) # saving a copy of cleaned annotation csv to preproc folder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f35a6082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImage(img_dir,filename):\n",
    "    '''\n",
    "    :param img_dir:\n",
    "    :param filename:\n",
    "    :return image:\n",
    "    '''\n",
    "    img_file=os.path.join(img_dir,filename)\n",
    "    img=cv2.imread(img_file)\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    # pad image to optimal input image dimension of [1024, 1024]\n",
    "    # padding to the left and the bottom of the image as it was mostly empty\n",
    "    pad_bot = height % 1024 \n",
    "    pad_lft = width % 1024\n",
    "    # pad the image\n",
    "    img = cv2.copyMakeBorder(img,0,pad_bot,pad_lft,0,cv2.BORDER_CONSTANT,value=[0,0,0])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "922fbb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tileImage(img):\n",
    "    '''\n",
    "    :param img:\n",
    "    :return list of coordinates:\n",
    "    :rtype list:\n",
    "    Objective: output a list of coordinates for the bounding boxes of the tiles\n",
    "    '''\n",
    "    tiles = [] # an empty list \n",
    "    for i in range(0,img.shape[0],1024):\n",
    "        for j in range(0,img.shape[1],1024):\n",
    "            #print(i, \" \", j)\n",
    "            #tile = [[j, i],[j, i+1024], [j+1024, i], [j+1024, i+1024]]\n",
    "            xmin = j\n",
    "            xmax = j + 1024\n",
    "            ymin = i\n",
    "            ymax = i + 1024\n",
    "            tiles.append([xmin,ymin,xmax,ymax])\n",
    "    #print(tiles)\n",
    "    return tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc5f346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertPoints(anno):\n",
    "    '''\n",
    "    :param anno:\n",
    "    :paramtype list:\n",
    "    :param img:\n",
    "    :paramtype numpy array:\n",
    "    :param annotab:\n",
    "    :paramtype pandas dataframe:\n",
    "    :param files:\n",
    "    :paramtype list:\n",
    "    :param classes:\n",
    "    :paramtype list:\n",
    "    :return dataset_dicts:\n",
    "    :rtype list:\n",
    "    Objective: iterate over each of the segmentations in the image and intersect them with the tile bounding boxes\n",
    "    '''\n",
    "    points = []\n",
    "                    \n",
    "    for x_coordinate in range(0,len(anno[\"all_points_x\"]),1):\n",
    "        points.append([anno[\"all_points_x\"][x_coordinate],anno[\"all_points_y\"][x_coordinate]])\n",
    "    \n",
    "    # remove empyt lists from the list of points\n",
    "    points = [x for x in points if x]\n",
    "    return points\n",
    "\n",
    "def transformPoints(points,xmin,ymin):\n",
    "    transformed_points = []\n",
    "    for point in points:\n",
    "        #print(p)\n",
    "        p2 = []\n",
    "        #print(type(p2[0]))\n",
    "        p2.append(point[0]-xmin)\n",
    "        p2.append(point[1]-ymin)\n",
    "        transformed_points.append(p2)\n",
    "    #print(transformed_points)\n",
    "    return transformed_points\n",
    "\n",
    "def findBoundingBox(points):\n",
    "    '''\n",
    "    :param points:\n",
    "    :paramtype list:  points forming one annotation converted to pair format, i.e. [[x,y],[x,y]...]\n",
    "    Objective: find the bounding box of an annotation\n",
    "    '''   \n",
    "    Sxmin=min(points,key=lambda x:x[0])[0]\n",
    "    Symin=min(points,key=lambda x:x[1])[1]\n",
    "    Sxmax=max(points,key=lambda x:x[0])[0]\n",
    "    Symax=max(points,key=lambda x:x[1])[1]\n",
    "    Segbbox = [Sxmin,Symin,Sxmax,Symax]\n",
    "    return Segbbox\n",
    "\n",
    "def intersectmask(anno,xmin, ymin, xmax, ymax):\n",
    "    '''\n",
    "    :param points:\n",
    "    :paramtype list: points forming one annotation converted to pair format, i.e. [[x,y],[x,y]...]\n",
    "    :param xmin:\n",
    "    :paramtype int:  left x coordinate of a tile \n",
    "    :param xmax:\n",
    "    :paramtype int:  right x coordinate of a tile \n",
    "    :param ymin:\n",
    "    :paramtype int:  upper y coordinate of a tile \n",
    "    :param ymax:\n",
    "    :paramtype int:  bottom y coordinate of a tile \n",
    "    Objective: iterate over each of the segmentations in the image and intersect them with the tile bounding boxes\n",
    "    '''    \n",
    "    intersect_point_list=[]\n",
    "    \n",
    "    # create shapely object for each tile and annotation\n",
    "    tilebox = Polygon([(xmin,ymin),(xmax,ymin),(xmax,ymax),(xmin,ymax)])\n",
    "    points = convertPoints(anno) # convert coordinates to points in [x,y] format\n",
    "    polygon_anno = Polygon(points)\n",
    "    polygon_anno = make_valid(polygon_anno) # all annotation should be valid after the make_valid\n",
    "    # it is ok for an annotation to be multipolygon and geometryCollection\n",
    "    \n",
    "    # create intersection between tile box and annotation\n",
    "    intersect_anno = polygon_anno.intersection(tilebox)\n",
    "    \n",
    "    # converting polygon_inters from shapely object to list of points\n",
    "    if (not intersect_anno.is_empty): #empty intersections are dropped\n",
    "        is_polygon = intersect_anno.geom_type=='Polygon'\n",
    "        is_polygon_multi = intersect_anno.geom_type=='MultiPolygon'\n",
    "        is_mutliothers = intersect_anno.geom_type=='GeometryCollection'\n",
    "        \n",
    "        if is_polygon or is_multipolygon or is_mutliothers: # points and lines are dropped\n",
    "            # layout three possible object types of intersected annotation\n",
    "            if is_polygon: \n",
    "                intersect_point_list = noHolePolygon(intersect_anno)\n",
    "            else: # finished one object type, two more to go\n",
    "                if is_multipolygon: \n",
    "                    # merge elements in a multipolygon to one\n",
    "                    for geom in intersect_anno.geoms:\n",
    "                        intersect_point_list.append(noHolePolygon(geom))\n",
    "                    \n",
    "                else: #is GeometryCollection\n",
    "                    for geom in intersect_anno.geoms:\n",
    "                        if geom.geom_type == 'Point' or geom.geom_type == 'LineString':\n",
    "                            continue #skip the rest of the code in the loop\n",
    "                        intersect_point_list = noHolePolygon(geom)\n",
    "    \n",
    "        # transform point to using tile coordinates      \n",
    "        transformed_point_list = transformPoints(intersect_point_list, xmin, ymin)\n",
    "    else:\n",
    "        transformed_point_list = []\n",
    "        \n",
    "    # reformat point list from [[x,y],[x,y]...] to [x,y,x,y,x,y,....]\n",
    "    transformed_point_list=[element for point in transformed_point_list for element in point]\n",
    "    \n",
    "    return transformed_point_list\n",
    "\n",
    "def IntersectSegmentations(img_dir,output_dir,tiles,img,annotab,file,classes):\n",
    "    '''\n",
    "    :param tiles:\n",
    "    :paramtype list:\n",
    "    :param img:\n",
    "    :paramtype numpy array:\n",
    "    :param annotab:\n",
    "    :paramtype pandas dataframe:\n",
    "    :param files:\n",
    "    :paramtype list:\n",
    "    :return records:\n",
    "    :rtype list:\n",
    "    Objective: iterate over each of the segmentations in the image and intersect them with the tile \n",
    "    '''\n",
    "    \n",
    "    filename=os.path.join(img_dir,file)\n",
    "    \n",
    "    # iterate over the tiles in an image\n",
    "    records=[] # a record contains all annotations in a tile, records contain all tiles in an image\n",
    "    for ind,tile in enumerate(tiles):\n",
    "        record = {}\n",
    "        record[\"filename\"] = tile_id + '.jpg'\n",
    "        record[\"image_id\"] = tile_id,\n",
    "        record[\"height\"] = 800\n",
    "        record[\"width\"] = 1333\n",
    "        record[\"annotations\"] = []\n",
    "        \n",
    "        xmin=tile[0]\n",
    "        ymin=tile[1]\n",
    "        xmax=tile[2]\n",
    "        ymax=tile[3]\n",
    "        # make a tile id using the xmin,ymin,xmax,ymax and the filename\n",
    "        tile_id = file[:-4] + '_'+ str(xmin)+\"_\"+str(ymin)+\"_\"+str(xmax)+\"_\"+str(ymax)\n",
    "        \n",
    "        #iterate over each annotation to find the ones intersecting the tile\n",
    "        subtab = annotab[annotab['filename'] == file]\n",
    "        for i in range(0,subtab.shape[0],1): \n",
    "            tab_rec = subtab.iloc[i]\n",
    "            # get annotation coordinates\n",
    "            anno = json.loads(tab_rec[\"region_shape_attributes\"]) \n",
    "            \n",
    "            # find intersection between an annotation and tiles\n",
    "            intersect_point_list = intersectmask(anno,xmin,ymin,xmax,ymax)\n",
    "            \n",
    "            # check whether intersection is empty\n",
    "            if len(intersect_point_list) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                # get its bounding box\n",
    "                Segbbox = findBoundingBox(intersect_point_list)\n",
    "                \n",
    "                # make a UID for non-empty intersect\n",
    "                uid = str(uuid.uuid4())\n",
    "                \n",
    "                # get annotation label \n",
    "                # input for mask rcnn require category_id to be int in the range of in the range [0, num_categories-1]\n",
    "                loadcldict = json.loads(tab_rec['region_attributes'])\n",
    "                category_id = classes.index(loadcldict['object'])\n",
    "                \n",
    "                #create annotations field that contains bbox,bbox_mode, category_id and segmentation\n",
    "                obj = {\n",
    "                    'segmentation': intersect_point_list,\n",
    "                    'bbox': Segbbox,\n",
    "                    'bbox_mode': 'BoxMode.XYXY_ABS',\n",
    "                    'category_id': category_id,\n",
    "                    'iscrowd':0\n",
    "                }\n",
    "                \n",
    "                record[\"annotations\"].append(obj)\n",
    "                \n",
    "        if len(record['annotations']) > 0:\n",
    "            #subset the image to the tile coordinates\n",
    "            subimg=img[ymin:ymax,xmin:xmax]\n",
    "            # write the tile image to the output directory\n",
    "            cv2.imwrite(os.path.join(output_dir,tile_id+'.jpg'),subimg)\n",
    "            records.append(record)\n",
    "    \n",
    "    return records\n",
    "\n",
    "def writeSegmentationCSV(dataset_dicts, output_dir):\n",
    "    '''\n",
    "    :param dataset_dicts: list[dict], each dict is a tiled imge,\n",
    "    :return: writes a csv file to result dir\n",
    "    \n",
    "    # Objective: Iterate over the dataset_dicts, each record will consist of filename, image_id, height, width, and annotations.\n",
    "    We want to iterate over each record and write each record to a line in the tsv file where the header line of the file\n",
    "    will be the keys of daatset_dict:'filename','image_id','height','width','annotations'.\n",
    "    '''\n",
    "    \n",
    "    import csv\n",
    "    with open(output_dir+\"regiondata_preprocessed_coco.csv\", \"w\") as csvfile:\n",
    "        \n",
    "        fieldnames = ['filename', 'image_id','height', 'width', 'annotations']\n",
    "        writer = csv.DictWriter(csvfile,fieldnames=fieldnames,delimiter='\\t')\n",
    "        writer.writeheader()\n",
    "        for ind1,record in enumerate(dataset_dicts):\n",
    "            for indo,obj in enumerate(record[\"annotations\"]):\n",
    "                writer.writerow(obj)\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8156f815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stained_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m dataset_dicts\u001b[38;5;241m=\u001b[39m[] \u001b[38;5;66;03m# a list of records (list of dictionaries named record)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indi,original_image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(files): \u001b[38;5;66;03m#iterate over each image\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mstained_image\u001b[49m)\n\u001b[1;32m      6\u001b[0m     img \u001b[38;5;241m=\u001b[39m readImage(img_dir,stained_image)\n\u001b[1;32m      7\u001b[0m     tiles \u001b[38;5;241m=\u001b[39m tileImage(img)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stained_image' is not defined"
     ]
    }
   ],
   "source": [
    "# main code BLOCK 2 \n",
    "## tiling\n",
    "dataset_dicts=[] # a list of records (list of dictionaries named record)\n",
    "for indi,original_image in enumerate(files): #iterate over each image\n",
    "    print(original_image)\n",
    "    img = readImage(img_dir,original_image)\n",
    "    tiles = tileImage(img)\n",
    "    records = IntersectSegmentations(img_dir,output_dir,tiles,img,annotab,original_image)\n",
    "    dataset_dicts.extend(records) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:shapely]",
   "language": "python",
   "name": "conda-env-shapely-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
