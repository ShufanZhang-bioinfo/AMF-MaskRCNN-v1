{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6809302",
   "metadata": {},
   "source": [
    "## test parallel inference on a MINE 2022 Axioscan7 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0611e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import copy\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import cv2\n",
    "from itertools import compress\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor,DefaultTrainer,HookBase\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer,ColorMode,GenericMask\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.evaluation import COCOEvaluator,inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader,DatasetMapper,build_detection_train_loader,MetadataCatalog,DatasetCatalog\n",
    "import detectron2.data.transforms as T\n",
    "import detectron2.utils.comm as comm\n",
    "\n",
    "import ray\n",
    "import time\n",
    "\n",
    "import uuid as uuid\n",
    "from operator import itemgetter\n",
    "import seaborn as sns\n",
    "\n",
    "import shapely\n",
    "import shapely.geometry\n",
    "from shapely.geometry import Polygon,MultiPolygon,GeometryCollection\n",
    "from shapely.validation import make_valid\n",
    "from shapely.geometry import mapping\n",
    "#import geopandas as gpd\n",
    "\n",
    "#import imgfileutils as imf\n",
    "#import segmentation_tools as sgt\n",
    "from aicsimageio import AICSImage, imread\n",
    "from skimage import measure, segmentation\n",
    "from skimage.measure import regionprops\n",
    "from skimage.color import label2rgb\n",
    "#import progressbar\n",
    "from IPython.display import display, HTML\n",
    "#from MightyMosaic import MightyMosaic\n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6199959d",
   "metadata": {},
   "source": [
    "## check available resources on the computer\n",
    "Total 20 cores\n",
    "Estimated time to do inference on 1 czi image is 40 min\n",
    "to finish inference on 337 accessions x 3 untreated blocks x 40 min = 40440 mins = 674 hrs = 28 days on one core or 2 days on 15 cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade0f297",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-27 16:39:17,679\tINFO worker.py:1642 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()\n",
    "ray.available_resources()['CPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db5ad336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup directory\n",
    "root = r'/Users/lovely_shufan/'\n",
    "project_dir = root + r'Dropbox (Edison_Lab@UGA)/AMF/AMF Imaging 2022/0_inference_using_MaskRCNN_2021/'\n",
    "data_dir = project_dir + r'0_raw_czi/GA_MINE_2022_imaged_by_Isabella_Wilson/'\n",
    "output_dir = project_dir + r'2_infer_result/GA_MINE_2022_imaged_by_Isabella_Wilson/'\n",
    "\n",
    "model_dir = root + r'Dropbox (Edison_Lab@UGA)/AMF/AMF Imaging 2021/2_computer_vision/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872b761",
   "metadata": {},
   "source": [
    "### Create a detectron2 config and a detectron2 DefaultPredictor to run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2287e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['root','AMF internal hypha','AMF external hypha','AMF arbuscule','AMF vesicle','AMF spore','others']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0788412",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg() # return default configuration\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")) # copy config files from open source projects\n",
    "\n",
    "# training configuration\n",
    "cfg.DATASETS.TEST=()\n",
    "cfg.DATALOADER.NUM_WORKERS=2\n",
    "#cfg.SOLVER.IMS_PER_BATCH=args.batch_size\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE=128 #Number of regions per image used to train RPN. faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES=len(classes)# (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT=2\n",
    "cfg.SEED=1\n",
    "cfg.AUG_FLAG=1\n",
    "\n",
    "# inference configuration\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8  # set threshold for this model\n",
    "cfg.MODEL.WEIGHTS=os.path.join(model_dir, \"Trainset1_model_best.pth\") # path to the best model trained\n",
    "cfg.MODEL.DEVICE='cpu' # use cpu for inference\n",
    "\n",
    "\n",
    "inf_metadata = MetadataCatalog.get(\"inference\").set(thing_classes=['root','AMF internal hypha','AMF external hypha','AMF arbuscule','AMF vesicle','AMF spore','others'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "531ad773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/27 19:09:46 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /Users/lovely_shufan/Dropbox (Edison_Lab@UGA)/AMF/AMF Imaging 2021/2_computer_vision/Trainset1_model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:fvcore.common.checkpoint:The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "predictor = DefaultPredictor(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f0bbf",
   "metadata": {},
   "source": [
    "### Perform inference on a test czi image\n",
    "1. by examine the output image with inferred segmentations, the model did better on centered axioscan 7 images. The model also have higher tendency to segment blue noise created by centering as external hyphae \n",
    "2. centered images tend to have root inferred twice in an image\n",
    "3. run time for doing inference on 10 scenes in an axioscan image took 1051 s or 17.5min, so the runtime for an image would be ~45min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "611dd793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centering2train(diff, img):\n",
    "    row = img.shape[0]\n",
    "    col = img.shape[1]\n",
    "    times = row * col\n",
    "    for i in range(0,3,1):\n",
    "        diffarray = np.repeat(diff[i], times, axis = 0)\n",
    "        diffmx = diffarray.reshape((row,col))\n",
    "        img[:,:,i] = np.add(img[:,:,i],diffmx)\n",
    "        img[img > 255] = 255\n",
    "        img[img < 0] = 0\n",
    "    return img\n",
    "\n",
    "def padImg(img, tilex, tiley):\n",
    "    '''\n",
    "    :param img:\n",
    "    :return padded img:\n",
    "    \n",
    "    :rtype ndnumpy.array:\n",
    "    Objective: output a padded image dividle by tile size\n",
    "    '''\n",
    "    y = img.shape[0]\n",
    "    x = img.shape[1]\n",
    "    pad_top = tiley - (y % tiley)\n",
    "    pad_lft = tilex - (x % tilex)\n",
    "    img = cv2.copyMakeBorder(img,pad_top,0,pad_lft,0,cv2.BORDER_CONSTANT,value=[0,0,0])\n",
    "    \n",
    "    return img\n",
    "\n",
    "def makeTiles(file, scene, img, tilex, tiley, output_dir):\n",
    "    '''\n",
    "    :param file: name of axioscan7 image file\n",
    "    :paramtype str:\n",
    "    :param scene: name of scene\n",
    "    :paramtype str:\n",
    "    :param img: \n",
    "    :paramtype ndnumpy.array:\n",
    "    :param tilesize: size of desired tile \n",
    "    :paramtype int:  \n",
    "    :param outputdir: \n",
    "    :paramtype str:\n",
    "\n",
    "    Objective: write tiled images to output dir\n",
    "    '''\n",
    "    for i in range(0,img.shape[0],tiley):\n",
    "        for j in range(0,img.shape[1],tilex):\n",
    "            #print(i, \" \", j)\n",
    "            #tile = [[j, i],[j, i+1024], [j+1024, i], [j+1024, i+1024]]\n",
    "            xmin = j\n",
    "            xmax = j + tilex\n",
    "            ymin = i\n",
    "            ymax = i + tiley\n",
    "            \n",
    "            subimg = img[ymin:ymax,xmin:xmax]\n",
    "            tile_id = file[:-4] + '_' +scene + '_' +str(xmin)+\"_\"+str(ymin)+\"_\"+str(xmax)+\"_\"+str(ymax)\n",
    "            \n",
    "            # write the tile image to the output directory\n",
    "            cv2.imwrite(os.path.join(output_dir,tile_id+'.png'),subimg)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e7bc20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBGRdiff = [16.42420848, 23.31838778, 34.18322437]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85f01c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "testimg = AICSImage(os.path.join(data_dir,'PI52606_1.czi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6098e5f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScanRegion1\n",
      "0_0_2560_1920\n",
      "0\n",
      "2560_0_5120_1920\n",
      "0\n",
      "5120_0_7680_1920\n",
      "0\n",
      "7680_0_10240_1920\n",
      "0\n",
      "10240_0_12800_1920\n",
      "0\n",
      "12800_0_15360_1920\n",
      "0\n",
      "15360_0_17920_1920\n",
      "0\n",
      "0_1920_2560_3840\n",
      "0\n",
      "2560_1920_5120_3840\n",
      "0\n",
      "5120_1920_7680_3840\n",
      "0\n",
      "7680_1920_10240_3840\n",
      "0\n",
      "10240_1920_12800_3840\n",
      "0\n",
      "12800_1920_15360_3840\n",
      "0\n",
      "15360_1920_17920_3840\n",
      "2\n",
      "0_3840_2560_5760\n",
      "0\n",
      "2560_3840_5120_5760\n",
      "0\n",
      "5120_3840_7680_5760\n",
      "0\n",
      "7680_3840_10240_5760\n",
      "0\n",
      "10240_3840_12800_5760\n",
      "1\n",
      "12800_0_15360_1920\n",
      "0\n",
      "15360_0_17920_1920\n",
      "0\n",
      "0_5760_2560_7680\n",
      "0\n",
      "2560_5760_5120_7680\n",
      "1\n",
      "5120_0_7680_1920\n",
      "0\n",
      "7680_0_10240_1920\n",
      "0\n",
      "10240_0_12800_1920\n",
      "0\n",
      "12800_0_15360_1920\n",
      "0\n",
      "15360_0_17920_1920\n",
      "0\n",
      "0_7680_2560_9600\n",
      "0\n",
      "2560_7680_5120_9600\n",
      "1\n",
      "5120_0_7680_1920\n",
      "0\n",
      "7680_0_10240_1920\n",
      "0\n",
      "10240_0_12800_1920\n",
      "0\n",
      "12800_0_15360_1920\n",
      "0\n",
      "15360_0_17920_1920\n",
      "0\n",
      "Time Elapsed:\t102.7714\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "imgidlist = []\n",
    "sceneidlist = []\n",
    "tileidlist = []\n",
    "classlist = []\n",
    "confscorelist=[]\n",
    "arealist = []\n",
    "\n",
    "for scene in testimg.scenes[1:2]:\n",
    "    print(scene)\n",
    "    \n",
    "    # apply contrast stretching to each scene\n",
    "    testimg.set_scene(scene)\n",
    "    #print(testimg.dims)\n",
    "    img = testimg.get_image_data(\"YXS\", T=0,C=0,Z=0) # numpy.ndarray\n",
    "    \n",
    "    # pad image\n",
    "    img = padImg(img, 2560, 1920)\n",
    "    \n",
    "    # centering\n",
    "    #imgorg = np.copy(img)\n",
    "    imgc = centering2train(trainBGRdiff, img)\n",
    "    #cv2.imshow('org',imgorg)\n",
    "    #cv2.imshow('orgcp',img)\n",
    "    #cv2.imshow('centered',imgc)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    #cv2.waitKey(1)\n",
    "\n",
    "    for i in range(0,img.shape[0],1920):\n",
    "        for j in range(0,img.shape[1],2560):\n",
    "            #print(i, \" \", j)\n",
    "            #tile = [[j, i],[j, i+1024], [j+1024, i], [j+1024, i+1024]]\n",
    "            xmin = j\n",
    "            xmax = j + 2560\n",
    "            ymin = i\n",
    "            ymax = i + 1920\n",
    "            \n",
    "            # tile name\n",
    "            tile_id = str(xmin)+\"_\"+str(ymin)+\"_\"+str(xmax)+\"_\"+str(ymax)\n",
    "            print(tile_id)\n",
    "            \n",
    "            # tiling\n",
    "            #subimg = imgorg[ymin:ymax,xmin:xmax]\n",
    "            subimgc = imgc[ymin:ymax,xmin:xmax]\n",
    "            \n",
    "            #cv2.imshow('org',subimg)\n",
    "            #cv2.imshow('orgcp',subimgc)\n",
    "            #cv2.imshow('centered',imgc)\n",
    "            #cv2.waitKey(0)\n",
    "            #cv2.destroyAllWindows()\n",
    "            #cv2.waitKey(1)\n",
    "            \n",
    "            # inference\n",
    "            #predictor = DefaultPredictor(cfg)\n",
    "            #outputs_org = predictor(subimg)\n",
    "            outputs_cen = predictor(subimgc)\n",
    "            \n",
    "            # inference outputs\n",
    "            clasind = outputs_cen['instances'].get('pred_classes')\n",
    "            allmasks=outputs_cen['instances'].get('pred_masks')\n",
    "            allscores = outputs_cen['instances'].get('scores')\n",
    "            \n",
    "            num_seg = clasind.size()[0]\n",
    "            #print(num_seg)\n",
    "            \n",
    "            if num_seg != 0: # only save an entry when the image contains a segmentation\n",
    "                imgidlist = imgidlist + np.repeat('PI52606_1', num_seg).tolist()\n",
    "                sceneidlist = sceneidlist + np.repeat(scene, num_seg).tolist()\n",
    "                tileidlist = tileidlist + np.repeat(tile_id, num_seg).tolist()\n",
    "                classlist = classlist + clasind.tolist()\n",
    "                confscorelist = confscorelist + allscores.tolist()\n",
    "                \n",
    "                # calculate the area of segmentation\n",
    "                v = Visualizer(subimgc[:, :, ::-1], MetadataCatalog.get(\"inference\"), scale=1.0)\n",
    "                for i in range(0,num_seg,1):\n",
    "                    locmask = np.asarray(allmasks[i,:,:])\n",
    "                    gmask = GenericMask(locmask,v.output.height,v.output.width)\n",
    "                    mergpolygon = gmask.polygons[0]\n",
    "                    all_points_x = mergpolygon[::2]\n",
    "                    all_points_y = mergpolygon[1::2]\n",
    "                    pgon = Polygon(zip(all_points_x,all_points_y))\n",
    "                    arealist.append(pgon.area)\n",
    "            # visualizer\n",
    "#             v = Visualizer(subimg[:, :, ::-1], MetadataCatalog.get(\"inference\"), scale=1.2)\n",
    "#             out = v.draw_instance_predictions(outputs_org[\"instances\"].to(\"cpu\"))\n",
    "#             out_img = out.get_image()[:, :, ::-1]\n",
    "#             cv2.imwrite(os.path.join(output_dir, \"_\".join([tile_id,'org.png'])), out_img)\n",
    "            \n",
    "#             v2 = Visualizer(subimgc[:, :, ::-1], MetadataCatalog.get(\"inference\"), scale=1.2)\n",
    "#             out2 = v2.draw_instance_predictions(outputs_cen[\"instances\"].to(\"cpu\"))\n",
    "#             out_img2 = out2.get_image()[:, :, ::-1]\n",
    "#             cv2.imwrite(os.path.join(output_dir, \"_\".join([tile_id,'centered.png'])), out_img2)\n",
    "\n",
    "# save inference results\n",
    "infresults = pd.DataFrame({\n",
    "    'filename': imgidlist,\n",
    "    'scene': sceneidlist,\n",
    "    'tile': tileidlist,\n",
    "    'annotations': classlist,\n",
    "    'area': arealist,\n",
    "    'confidenceScore': confscorelist})\n",
    "infresults.to_csv(os.path.join(output_dir, \"infresults.txt\"), index=False)            \n",
    "    \n",
    "print('Time Elapsed:\\t{:.4f}'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88141396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:detectron2-py38]",
   "language": "python",
   "name": "conda-env-detectron2-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
